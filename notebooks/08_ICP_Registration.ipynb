{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open3D Guide: 8. ICP Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This tutorial demonstrates the ICP (Iterative Closest Point) registration algorithm. It has been a mainstay of geometric registration in both research and industry for many years. The input are two point clouds and an initial transformation that roughly aligns the source point cloud to the target point cloud. The output is a refined transformation that tightly aligns the two point clouds. A helper function draw_registration_result visualizes the alignment during the registration process. In this tutorial, we show two ICP variants, the point-to-point ICP and the point-to-plane ICP [Rusinkiewicz2001].\n",
    ">\n",
    "> Both [ICP registration](https://www.open3d.org/docs/latest/tutorial/Advanced/global_registration.html) and [Colored point cloud registration](https://www.open3d.org/docs/latest/tutorial/Advanced/colored_pointcloud_registration.html) are known as **local registration methods** because they rely on a rough alignment as initialization. Prior to a local registration we need some kind of [**global registration**](https://www.open3d.org/docs/latest/tutorial/Advanced/global_registration.html). This family of algorithms do not require an alignment for initialization. They usually produce less tight alignment results and are used as initialization of the local methods.\n",
    "\n",
    "**This notebook deals with the local registration approach ICP**: we give a source and target point cloud already aligned and we obtain a more tight alignment.\n",
    "\n",
    "**IMPORTANT: The point-to-plane ICP algorithm uses point normals; we need to estimate them if they are not available**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources: \n",
    "\n",
    "- ICP: [https://www.open3d.org/docs/latest/tutorial/Basic/icp_registration.html](https://www.open3d.org/docs/latest/tutorial/Basic/icp_registration.html).\n",
    "- Global registrations: [https://www.open3d.org/docs/latest/tutorial/Advanced/global_registration.html](https://www.open3d.org/docs/latest/tutorial/Advanced/global_registration.html).\n",
    "- Colored point cloud registrations: [https://www.open3d.org/docs/latest/tutorial/Advanced/colored_pointcloud_registration.html](https://www.open3d.org/docs/latest/tutorial/Advanced/colored_pointcloud_registration.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of contents:\n",
    "\n",
    "- Prepare Input Data: Source and Target\n",
    "- Point-to-point ICP\n",
    "  - `o3d.pipelines.registration.registration_icp`\n",
    "  - `o3d.pipelines.registration.TransformationEstimationPointToPoint()`\n",
    "- Point-to-plane ICP\n",
    "  - `o3d.pipelines.registration.TransformationEstimationPointToPlane()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# Add the directory containing 'examples' to the Python path\n",
    "notebook_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(notebook_directory)  # Parent directory\n",
    "sys.path.append(parent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "from examples import open3d_example as o3dex\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Input Data: Source and Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section:\n",
    "\n",
    "- I load a triangle mesh and obtain a point cloud from it\n",
    "- Then, I create a copy of the point cloud which is shifted and rotated\n",
    "  - The transformation is parametrized\n",
    "  - I also compute the inverse with an error: this will be the initial alignment\n",
    "- Then, both point clouds (source and target) are visualized\n",
    "- Finally, the current registration error is evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper visualization function\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    # Since the functions transform and paint_uniform_color change the point cloud,\n",
    "    # we call copy.deepcopy to make copies and protect the original point clouds.\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create a transformation matrix\n",
    "def create_transformation_matrix(d, a_deg):\n",
    "    a_rad = np.radians(a_deg)  # Convert angle from degrees to radians\n",
    "    # Define the rotation matrix around the axis (1, 1, 1)\n",
    "    R = o3d.geometry.get_rotation_matrix_from_axis_angle(np.array([1.0, 1.0, 1.0]) * a_rad)\n",
    "    # Define the translation vector (d, d, d)\n",
    "    T = np.array([d, d, d])\n",
    "    # Create a homogeneous transformation matrix\n",
    "    transform = np.eye(4)\n",
    "    transform[:3, :3] = R\n",
    "    transform[:3, 3] = T\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mesh from a PLY file\n",
    "mesh = o3d.io.read_triangle_mesh(\"../models/monkey.ply\")\n",
    "mesh.compute_vertex_normals()\n",
    "\n",
    "# Convert the mesh to a point cloud by sampling\n",
    "pcd = mesh.sample_points_poisson_disk(number_of_points=2048)\n",
    "pcd.estimate_normals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the AABB and its diagonal\n",
    "aabb = pcd.get_axis_aligned_bounding_box()\n",
    "aabb_diagonal_length = np.linalg.norm(aabb.get_extent())\n",
    "\n",
    "# Set the translation distance to 10% of the AABB diagonal\n",
    "d = 0.2 * aabb_diagonal_length\n",
    "# Define the rotation angle (degrees)\n",
    "a = 20\n",
    "\n",
    "# Create the transformation matrix\n",
    "transformation_matrix = create_transformation_matrix(d, a)\n",
    "# Create the inverse transformation but going back only 50%, i.e., with an error\n",
    "# This matrix would be like the initial transformation/alignment obtained from\n",
    "# a global registration\n",
    "transformation_matrix_aprox_inv = create_transformation_matrix(-1.0*0.5*d, -1.0*0.5*a)\n",
    "\n",
    "# Apply the transformation to the point cloud to create a new point cloud\n",
    "pcd_transformed = copy.deepcopy(pcd)\n",
    "pcd_transformed = pcd_transformed.transform(transformation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.88181977 -0.26909475  0.38727498  0.75099655]\n",
      " [ 0.38727498  0.88181977 -0.26909475  0.75099655]\n",
      " [-0.26909475  0.38727498  0.88181977  0.75099655]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(transformation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.96976953  0.18700199 -0.15677152 -0.37549828]\n",
      " [-0.15677152  0.96976953  0.18700199 -0.37549828]\n",
      " [ 0.18700199 -0.15677152  0.96976953 -0.37549828]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(transformation_matrix_aprox_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set source and target\n",
    "source = pcd_transformed\n",
    "target = pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize source and target\n",
    "draw_registration_result(source, target, np.eye(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1877491386523795\n"
     ]
    }
   ],
   "source": [
    "# Visuaalize source and target with the approximate alignment,\n",
    "# i.e., after obtaining an initial transformation from global registration\n",
    "threshold = 0.05*aabb_diagonal_length\n",
    "print(threshold)\n",
    "trans_init = transformation_matrix_aprox_inv\n",
    "draw_registration_result(source, target, trans_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial alignment\n",
      "RegistrationResult with fitness=3.789062e-01, inlier_rmse=1.066932e-01, and correspondence_set size of 776\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate initial alignment\n",
    "# The function evaluate_registration calculates two main metrics:\n",
    "# - fitness, which measures the overlapping area (# of inlier correspondences / # of points in target). The higher the better.\n",
    "# - inlier_rmse, which measures the RMSE of all inlier correspondences. The lower the better.\n",
    "print(\"Initial alignment\")\n",
    "evaluation = o3d.pipelines.registration.evaluate_registration(\n",
    "    source, target, threshold, trans_init)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point-to-point ICP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the ICP algorithm iterates over two steps:\n",
    "\n",
    "1. Find correspondence set `K={(p,q)}` from target point cloud P, and source point cloud Q transformed with current transformation matrix T\n",
    "2. Update the transformation T by minimizing an objective function E(T) defined over the correspondence set K.\n",
    "\n",
    "Different variants of ICP use different objective functions E(T): [BeslAndMcKay1992] [ChenAndMedioni1992] [Park2017].\n",
    "\n",
    "We first show a point-to-point ICP algorithm [BeslAndMcKay1992] using the objective\n",
    "\n",
    "    E(T) = sum(abs(p − T*q); (p,q) in K)\n",
    "\n",
    "The class `TransformationEstimationPointToPoint` provides functions to compute the residuals and Jacobian matrices of the point-to-point ICP objective. The function `registration_icp` takes it as a parameter and runs point-to-point ICP to obtain the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply point-to-point ICP\n",
      "RegistrationResult with fitness=9.980469e-01, inlier_rmse=5.909662e-02, and correspondence_set size of 2044\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.94931697  0.26681441 -0.16615461 -0.77200859]\n",
      " [-0.19005553  0.90829013  0.37267672 -0.82042534]\n",
      " [ 0.25035211 -0.32220973  0.91296479 -0.61875355]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Apply point-to-point ICP\")\n",
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    source, target, threshold, trans_init,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "print(reg_p2p)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2p.transformation)\n",
    "draw_registration_result(source, target, reg_p2p.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.98516835, -0.08452151,  0.14932993,  0.01652035],\n",
       "       [ 0.08387797,  0.99641951,  0.01061385, -0.0011547 ],\n",
       "       [-0.14969235,  0.00206906,  0.98873046,  0.01291504],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The result multiplied by the transformation_matrix should yield the identity \n",
    "reg_p2p.transformation @ transformation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegistrationResult with fitness=1.000000e+00, inlier_rmse=4.020841e-15, and correspondence_set size of 2048\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.88181977  0.38727498 -0.26909475 -0.75099655]\n",
      " [-0.26909475  0.88181977  0.38727498 -0.75099655]\n",
      " [ 0.38727498 -0.26909475  0.88181977 -0.75099655]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# By default, registration_icp runs until convergence or reaches a maximum number of iterations (30 by default).\n",
    "# It can be changed to allow more computation time and to improve the results further.\n",
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    source, target, threshold, trans_init,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "    o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=2000))\n",
    "print(reg_p2p)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2p.transformation)\n",
    "draw_registration_result(source, target, reg_p2p.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  4.64382502e-16,  9.54172502e-16,\n",
       "        -5.55111512e-16],\n",
       "       [ 6.82637200e-16,  1.00000000e+00,  2.56102925e-16,\n",
       "         8.88178420e-16],\n",
       "       [ 5.85971036e-16,  2.06954757e-16,  1.00000000e+00,\n",
       "        -4.44089210e-16],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The result multiplied by the transformation_matrix should yield the identity \n",
    "reg_p2p.transformation @ transformation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point-to-plane ICP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point-to-plane ICP algorithm [ChenAndMedioni1992] uses a different objective function\n",
    "\n",
    "    E(T) = sum(dot((p − T*q), np)^2; (p,q) in K)\n",
    "\n",
    "where np is the normal of point p.\n",
    "\n",
    "[Rusinkiewicz2001] has shown that the point-to-plane ICP algorithm has a faster convergence speed than the point-to-point ICP algorithm.\n",
    "\n",
    "`registration_icp` is called with a different parameter `TransformationEstimationPointToPlane`. Internally, this class implements functions to compute the residuals and Jacobian matrices of the point-to-plane ICP objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply point-to-plane ICP\n",
      "RegistrationResult with fitness=1.000000e+00, inlier_rmse=3.497597e-16, and correspondence_set size of 2048\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.88181977  0.38727498 -0.26909475 -0.75099655]\n",
      " [-0.26909475  0.88181977  0.38727498 -0.75099655]\n",
      " [ 0.38727498 -0.26909475  0.88181977 -0.75099655]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Apply point-to-plane ICP\")\n",
    "reg_p2l = o3d.pipelines.registration.registration_icp(\n",
    "    source, target, threshold, trans_init,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPlane())\n",
    "print(reg_p2l)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2l.transformation)\n",
    "draw_registration_result(source, target, reg_p2l.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
